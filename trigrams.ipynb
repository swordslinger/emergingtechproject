{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks For Emerging Technologies\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports.\n",
    "\n",
    "# Efficent data processing.\n",
    "import itertools\n",
    "\n",
    "# Efficent data structures. \n",
    "import collections   \n",
    "\n",
    "# Used for handling file directorys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 Third-order letter approximation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select five free English works in Plain Text UTF8 format from Project Gutenberg. Use them to create a model of the English language as follows. Remove any preamble and postamble. Remove all characters except for (ASCII) letters (uppercase and lowercase), full stops, and spaces. Make all letters uppercase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Explenation\n",
    "what are we doing?<br>\n",
    "Below we making use the listdir method in the os module to list all the files in the englishworks folder.<br>\n",
    "\n",
    "why are we doing this?<br>\n",
    "we are ensuring englishworks is populated with 5 text files before processing in our task.\n",
    "\n",
    "what does the os.listdir function do?<br>\n",
    "\"Return a list containing the names of the entries in the directory given by path.\" <br>\n",
    "\n",
    "References <br>\n",
    "os.listdir function reference : https://docs.python.org/3/library/os.html#os.listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in 5 English Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prideandpredjudice.txt',\n",
       " 'williamsedly.txt',\n",
       " 'theliteratureofthehighlanders.txt',\n",
       " 'chiletodayandtomorrow.txt',\n",
       " 'theeast.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the files in the englishworks folder.\n",
    "os.listdir('englishworks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code explanation generators\n",
    "What are we doing?<br>\n",
    "\n",
    "Why are we doing this? <br>\n",
    "\n",
    "what do generators do? <br>\n",
    "Reference <br>\n",
    "Generators: https://realpython.com/introduction-to-python-generators/\n",
    "            https://docs.python.org/3/howto/functional.html#generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code explanation iterools\n",
    "What are we doing?<br>\n",
    "\n",
    "Why are we doing this? <br>\n",
    "\n",
    "what do  do? <br>\n",
    "References <br>\n",
    "Dropwhile: https://docs.python.org/3/library/itertools.html#itertools.dropwhile <br>\n",
    "Takewhile: https://docs.python.org/3/library/itertools.html#itertools.takewhile\n",
    "itertools module: https://realpython.com/python-itertools/ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code explanation joining filepaths\n",
    "What are we doing?<br>\n",
    "\n",
    "Why are we doing this? <br>\n",
    "\n",
    "what do  do? <br>\n",
    "References for os.path.join explanation and usage<br>\n",
    "os.path.join: https://docs.python.org/3/library/os.path.html#os.path.join <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code explanation with statement\n",
    "\n",
    "References for with statement explanation and usage<br>\n",
    "with statement: https://realpython.com/python-with-statement/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following was adapted from a response from ChatGPT in conjunction with a jupyter notebook. <br>\n",
    "https://chatgpt.com/share/66ffdf0f-4094-800d-9ae9-63ffb9b20043 <br>\n",
    "https://github.com/ianmcloughlin/2425_emerging_technologies/blob/main/02_language_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intilize empty list to store text from 5 .txt files\n",
    "english = []\n",
    "\n",
    "# iterates over each text file in the english works directory.\n",
    "for filepath in os.listdir('englishworks'):\n",
    "\n",
    "    # for each text file in the english works directory add \"/englishworks\" to the start of the text file. \n",
    "    englishBook = os.path.join('englishworks', filepath)\n",
    "\n",
    "    # open the text file for reading.\n",
    "    with open(englishBook) as f:\n",
    "\n",
    "        # Drops anything before '*** START' line from the text fie being read.\n",
    "        # Returns a generator/lazy list from '*** START' till end of the text file\n",
    "        fcontents = itertools.dropwhile(lambda x: '*** START' not in x, f)\n",
    "\n",
    "        # This generator is chained with the previous generator to keep lines until '*** End'.\n",
    "        # Returns a generator/lazy list from '*** START' till the line before '*** END'\n",
    "        fcontents = itertools.takewhile(lambda x: '*** END' not in x, fcontents)\n",
    "\n",
    "        # The text from '*** START' line till before '*** END' line is read from each file.\n",
    "        # The '*** START' line is dropped.\n",
    "        # Each proccesed text file is appened to the one before it until every file is read.\n",
    "        english = english + list(fcontents)[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to string\n",
    "words = ' '.join(english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characters to be kept \n",
    "keep = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned text\n",
    "# cleanedwords =''.join(c for c in words if c in keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned text\n",
    "cleanedwords=''.join(filter(lambda x: x in keep,words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert cleaned text all uppercase\n",
    "cleanedwords = words.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts each character occurance\n",
    "counts = collections.Counter(cleanedwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://realpython.com/python-filter-function/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 495684),\n",
       " ('E', 251123),\n",
       " ('T', 175763),\n",
       " ('A', 164368),\n",
       " ('O', 148175),\n",
       " ('I', 143802),\n",
       " ('N', 143682),\n",
       " ('S', 128820),\n",
       " ('R', 125097),\n",
       " ('H', 119380),\n",
       " ('L', 84993),\n",
       " ('D', 79753),\n",
       " ('C', 58997),\n",
       " ('U', 53704),\n",
       " ('F', 48766),\n",
       " ('M', 48697),\n",
       " ('G', 39323),\n",
       " ('W', 39138),\n",
       " ('Y', 36996),\n",
       " ('P', 36043),\n",
       " ('B', 31221),\n",
       " ('V', 20278),\n",
       " ('.', 18588),\n",
       " ('K', 10785),\n",
       " ('X', 3462),\n",
       " ('J', 2692),\n",
       " ('Q', 2416),\n",
       " ('Z', 1810)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IT': 2,\n",
       " 'T ': 3,\n",
       " ' I': 3,\n",
       " 'IS': 2,\n",
       " 'S ': 1,\n",
       " ' W': 1,\n",
       " 'WH': 1,\n",
       " 'HA': 1,\n",
       " 'AT': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing dimodel\n",
    "dimodel = {}\n",
    "dimodel\n",
    "testText = \"IT IS WHAT IT IS\"\n",
    "testcleanedText = ''.join(c for c in testText if c in keep)\n",
    "\n",
    "for i in range(1, len(testcleanedText)):\n",
    "    digram = testcleanedText[i-1:i+1]\n",
    "    dimodel[digram] = dimodel.get(digram, 0) + 1\n",
    "\n",
    "dimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing trimodel\n",
    "testrimodel = {}\n",
    "testrimodel\n",
    "for i in range(1, len(testcleanedText)):\n",
    "    trigram = testcleanedText[i-1:i+2]\n",
    "    testrimodel[trigram] = testrimodel.get(trigram,0) + 1\n",
    "    \n",
    " # testrimodel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create a trigram model by counting the number of times each sequence of three characters (that is, each trigram) appears. You can design your own data structure for storing the results but explain your design and its rationale in your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimodel = {}\n",
    "trimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(cleanedwords)- 2):\n",
    "    trigram = cleanedwords[i: i+3]\n",
    "    trimodel[trigram] = trimodel.get(trigram,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimodel.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen2 = \"TH\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringLength = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
