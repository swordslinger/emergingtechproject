{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks For Emerging Technologies\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports.\n",
    "\n",
    "# Efficent data processing.\n",
    "import itertools\n",
    "\n",
    "# Efficent data structures. \n",
    "import collections   \n",
    "\n",
    "# Used for handling file directorys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 Third-order letter approximation model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select five free English works in Plain Text UTF8 format from Project Gutenberg. Use them to create a model of the English language as follows. Remove any preamble and postamble. Remove all characters except for (ASCII) letters (uppercase and lowercase), full stops, and spaces. Make all letters uppercase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Explenation\n",
    "what are we doing?<br>\n",
    "Below we making use the listdir method in the os module to list all the files in the englishworks folder.<br>\n",
    "\n",
    "why are we doing this?<br>\n",
    "we are ensuring englishworks is populated with 5 text files before processing in our task.\n",
    "\n",
    "what does the os.listdir function do?<br>\n",
    "\"Return a list containing the names of the entries in the directory given by path.\" <br>\n",
    "\n",
    "References <br>\n",
    "os.listdir function reference : https://docs.python.org/3/library/os.html#os.listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in 5 English Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prideandpredjudice.txt',\n",
       " 'williamsedly.txt',\n",
       " 'theliteratureofthehighlanders.txt',\n",
       " 'chiletodayandtomorrow.txt',\n",
       " 'theeast.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the files in the englishworks folder.\n",
    "os.listdir('englishworks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code explanation generators\n",
    "What are we doing?<br>\n",
    "itertools.takewhile and itertools.drop while both return generators.<br>\n",
    "by passing the result of itertools.takewhile <br>\n",
    "into itertools.drop while we are chaining generators to filter text without ever <br>\n",
    "reading the file contents into memory.\n",
    "\n",
    "Why are we doing this? <br>\n",
    "This is simply a really memory efficent way of handling the data <br>\n",
    "only turning the chained generators result into a list when we have to\n",
    "while promoting short and concise code.\n",
    "\n",
    "what are generators? <br>\n",
    "generators are a special type of function that return lazy iterator <br>\n",
    "that is consumed upon being read.\n",
    "\n",
    "References <br> \n",
    "Generators: https://realpython.com/introduction-to-python-generators/<br>\n",
    "&emsp; &emsp; &emsp; &emsp; &nbsp;https://docs.python.org/3/howto/functional.html#generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code explanation iterools\n",
    "What are we doing?<br>\n",
    "The contents of the individual text files are read from the '*** START' line inclusive <br>\n",
    "till the '*** END' non inclusive\n",
    "\n",
    "Why are we doing this? <br>\n",
    "the itertools modules are concepts borrowed from functional programming.<br>\n",
    "we are using the iterools module, .dropwhile methood and the takewhile <br> method\n",
    "for 2 reasons. 1. Lazy lists: lines are generated by an iterable one at a time. <br>\n",
    "2.Lazy Evaluation: This iterable is does not start generating values until it is iterated over. <br>\n",
    "Beacause we only convert fcontents to a list when we need it, the use of 1. and 2. make this <br>\n",
    "a really memory efficent solution.\n",
    "\n",
    "\n",
    "what does fcontents = \"itertools.dropwhile\" and itertools.takewhile  do? <br>\n",
    "itertools.dropwhile takes a single argument function that returns true or false and an iterable as paramaters. <br> \n",
    "while the function is returning true dont read in any values,if/when it returns false return all the remaining elements in a generator<br>\n",
    " <br>\n",
    "itertools.takewhile takes a single argument function that returns true or false and an iterable as paramaters. <br> \n",
    "while the function is returning true read in values, if/when it returns false return all elements up to that point in generator.\n",
    "\n",
    "References <br>\n",
    "Dropwhile: https://docs.python.org/3/library/itertools.html#itertools.dropwhile <br>\n",
    "Takewhile: https://docs.python.org/3/library/itertools.html#itertools.takewhile\n",
    "itertools module: https://realpython.com/python-itertools/ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code explanation joining filepaths\n",
    "What are we doing?<br>\n",
    "For each text file in english works we combine the \"englishworks\" directory and the indiviudal text file into a single path.\n",
    "\n",
    "Why are we doing this? <br>\n",
    "We are doing this so we have the nessciary path to open each file. <br>\n",
    "\n",
    "what does os.path.join do? <br>\n",
    "os.path.join is a method in the OS module that combines directory and filenames into a single path with seperators. <br>\n",
    "Refernces for os.path.join explanation and usage<br>\n",
    "os.path.join: https://docs.python.org/3/library/os.path.html#os.path.join <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code explanation with statement\n",
    "What are we doing? <br>\n",
    "We are opening an individual text file in the english works directory to be read.\n",
    "\n",
    "Why are we doing this? <br>\n",
    "We are doing this so we can process each text file\n",
    "\n",
    "what does \"with open(filename) as f:\" do? <br>\n",
    "The with statement is known as a runtime context manager in python. Its a way of managing resoruces <br>\n",
    "such as but not limited to locks, network connections and files. This under the hood handles writing to <br>\n",
    "the file and closing the file. Its visually a bit more elegant then a try catch block and as it takes care <br>\n",
    "of manging the file we dont have to worry about memory leaks from forgetting to close it manually. <br>\n",
    "\n",
    "References for with statement explanation and usage<br>\n",
    "with statement: https://realpython.com/python-with-statement/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following was adapted from a response from ChatGPT in conjunction with a jupyter notebook. <br>\n",
    "https://chatgpt.com/share/66ffdf0f-4094-800d-9ae9-63ffb9b20043 <br>\n",
    "https://github.com/ianmcloughlin/2425_emerging_technologies/blob/main/02_language_models.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intilize empty list to store text from 5 .txt files\n",
    "english = []\n",
    "\n",
    "# iterates over each text file in the english works directory.\n",
    "for filepath in os.listdir('englishworks'):\n",
    "\n",
    "    # for each text file in the english works directory add \"/englishworks\" to the start of the text file. \n",
    "    englishBook = os.path.join('englishworks', filepath)\n",
    "\n",
    "    # open the text file for reading.\n",
    "    with open(englishBook) as f:\n",
    "\n",
    "        # Drops anything before '*** START' line from the text fie being read.\n",
    "        # Returns a generator from '*** START' till end of the text file\n",
    "        fcontents = itertools.dropwhile(lambda x: '*** START' not in x, f)\n",
    "\n",
    "        # This generator is chained with the previous generator to keep lines until '*** End'.\n",
    "        # Returns a generator from '*** START' till the line before '*** END'\n",
    "        fcontents = itertools.takewhile(lambda x: '*** END' not in x, fcontents)\n",
    "\n",
    "        # The text from '*** START' line till before '*** END' line is read from each file.\n",
    "        # The '*** START' line is dropped.\n",
    "        # Each proccesed text file is appened to the one before it until every file is read.\n",
    "        english = english + list(fcontents)[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to string\n",
    "words = ' '.join(english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Characters to be kept \n",
    "keep = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz .'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned text\n",
    "# cleanedwords =''.join(c for c in words if c in keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned text\n",
    "cleanedwords=''.join(filter(lambda x: x in keep,words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert cleaned text all uppercase\n",
    "cleanedwords = words.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts each character occurance\n",
    "counts = collections.Counter(cleanedwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "https://realpython.com/python-filter-function/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 495684),\n",
       " ('E', 251123),\n",
       " ('T', 175763),\n",
       " ('A', 164368),\n",
       " ('O', 148175),\n",
       " ('I', 143802),\n",
       " ('N', 143682),\n",
       " ('S', 128820),\n",
       " ('R', 125097),\n",
       " ('H', 119380),\n",
       " ('L', 84993),\n",
       " ('D', 79753),\n",
       " ('C', 58997),\n",
       " ('U', 53704),\n",
       " ('\\n', 49528),\n",
       " ('F', 48766),\n",
       " ('M', 48697),\n",
       " ('G', 39323),\n",
       " ('W', 39138),\n",
       " ('Y', 36996),\n",
       " ('P', 36043),\n",
       " (',', 33953),\n",
       " ('B', 31221),\n",
       " ('V', 20278),\n",
       " ('.', 18588),\n",
       " ('K', 10785),\n",
       " ('_', 5522),\n",
       " (';', 4557),\n",
       " ('“', 3891),\n",
       " ('-', 3879),\n",
       " ('”', 3783),\n",
       " ('X', 3462),\n",
       " ('’', 3072),\n",
       " ('0', 3035),\n",
       " ('J', 2692),\n",
       " ('1', 2465),\n",
       " ('Q', 2416),\n",
       " ('—', 1903),\n",
       " ('Z', 1810),\n",
       " (':', 1347),\n",
       " ('2', 1223),\n",
       " ('8', 1127),\n",
       " ('3', 949),\n",
       " ('!', 919),\n",
       " ('5', 880),\n",
       " ('9', 817),\n",
       " ('4', 796),\n",
       " ('7', 791),\n",
       " ('?', 756),\n",
       " ('6', 655),\n",
       " ('(', 486),\n",
       " (')', 486),\n",
       " ('[', 357),\n",
       " (']', 357),\n",
       " ('‘', 327),\n",
       " ('É', 260),\n",
       " ('Ó', 137),\n",
       " ('Á', 126),\n",
       " ('À', 92),\n",
       " ('&', 87),\n",
       " ('Í', 82),\n",
       " ('*', 78),\n",
       " ('Ñ', 78),\n",
       " ('─', 71),\n",
       " ('£', 53),\n",
       " ('Ò', 43),\n",
       " ('Æ', 42),\n",
       " ('Ù', 42),\n",
       " ('Â', 24),\n",
       " ('=', 24),\n",
       " ('{', 22),\n",
       " ('/', 18),\n",
       " ('Œ', 16),\n",
       " ('^', 14),\n",
       " ('$', 14),\n",
       " ('Ê', 13),\n",
       " ('Ì', 13),\n",
       " ('°', 13),\n",
       " ('–', 12),\n",
       " ('·', 10),\n",
       " ('Ô', 10),\n",
       " ('}', 8),\n",
       " ('●', 7),\n",
       " ('È', 7),\n",
       " ('Ú', 5),\n",
       " ('Ã', 5),\n",
       " ('½', 5),\n",
       " ('Ă', 4),\n",
       " ('º', 3),\n",
       " ('Û', 3),\n",
       " ('′', 3),\n",
       " ('Î', 2),\n",
       " ('Ü', 2),\n",
       " ('Ū', 1),\n",
       " ('Ĕ', 1),\n",
       " ('Ï', 1),\n",
       " ('Ŏ', 1),\n",
       " ('„', 1),\n",
       " ('″', 1),\n",
       " ('⁂', 1)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IT': 2,\n",
       " 'T ': 3,\n",
       " ' I': 3,\n",
       " 'IS': 2,\n",
       " 'S ': 1,\n",
       " ' W': 1,\n",
       " 'WH': 1,\n",
       " 'HA': 1,\n",
       " 'AT': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing dimodel\n",
    "dimodel = {}\n",
    "dimodel\n",
    "testText = \"IT IS WHAT IT IS\"\n",
    "testcleanedText = ''.join(c for c in testText if c in keep)\n",
    "\n",
    "for i in range(1, len(testcleanedText)):\n",
    "    digram = testcleanedText[i-1:i+1]\n",
    "    dimodel[digram] = dimodel.get(digram, 0) + 1\n",
    "\n",
    "dimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing trimodel\n",
    "testrimodel = {}\n",
    "testrimodel\n",
    "for i in range(1, len(testcleanedText)):\n",
    "    trigram = testcleanedText[i-1:i+2]\n",
    "    testrimodel[trigram] = testrimodel.get(trigram,0) + 1\n",
    "    \n",
    " # testrimodel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create a trigram model by counting the number of times each sequence of three characters (that is, each trigram) appears. You can design your own data structure for storing the results but explain your design and its rationale in your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimodel = {}\n",
    "trimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(cleanedwords)- 2):\n",
    "    trigram = cleanedwords[i: i+3]\n",
    "    trimodel[trigram] = trimodel.get(trigram,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trimodel.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen2 = \"TH\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringLength = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
